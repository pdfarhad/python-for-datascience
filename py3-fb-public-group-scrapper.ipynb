{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import json\n",
    "import datetime\n",
    "import csv\n",
    "import time\n",
    "import codecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "app_id = \"1192796350809849\"\n",
    "app_secret = \"585a729a44bb655f2cd6ef954e191a79\"\n",
    "access_token = app_id +\"|\"+ app_secret\n",
    "group_id = '172177269650835'#'publicserviceinnovationblog'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def request_until_completed(url):\n",
    "    req = urllib.request.Request(url)\n",
    "    success = False\n",
    "    while success is False:\n",
    "        try: \n",
    "            response = urllib.request.urlopen(req)\n",
    "            if response.getcode() == 200:\n",
    "                success = True\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            time.sleep(5)\n",
    "\n",
    "            print(\"Error for URL %s: %s\" % (url, datetime.datetime.now()))\n",
    "            print(\"Retrying.\")\n",
    "\n",
    "    return response.read().decode(response.headers.get_content_charset())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def unicode_normalize(text):\n",
    "    return text.translate({ 0x2018:0x27, 0x2019:0x27, 0x201C:0x22, 0x201D:0x22,\n",
    "                            0xa0:0x20 })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://graph.facebook.com/172177269650835/feed/?fields=message,link,created_time,type,name,id,likes.limit(1).summary(true),comments.limit(1).summary(true),shares&limit=1&access_token=1192796350809849|585a729a44bb655f2cd6ef954e191a79\n",
      "{'data': [{'name': 'একটি পরিচ্ছন্ন সরকারি হাসপাতাল', 'id': '172177269650835_635087893359768', 'type': 'link', 'comments': {'data': [{'id': '635156986686192', 'from': {'name': 'Manik Mahmud', 'id': '10153892048956582'}, 'created_time': '2016-12-18T09:05:56+0000', 'message': 'Sirazul Khan স্যার অনুগ্রহ করে মন্তব্য করতে পারেন।'}], 'summary': {'total_count': 4, 'can_comment': False, 'order': 'chronological'}, 'paging': {'cursors': {'after': 'WTI5dGJXVnVkRjlqZAFhKemIzSTZAOak0xTVRVMk9UZAzJOamcyTVRreU9qRTBPREl3TlRFNU5UWT0ZD', 'before': 'WTI5dGJXVnVkRjlqZAFhKemIzSTZAOak0xTVRVMk9UZAzJOamcyTVRreU9qRTBPREl3TlRFNU5UWT0ZD'}, 'next': 'https://graph.facebook.com/v2.8/172177269650835_635087893359768/comments?access_token=1192796350809849%7C585a729a44bb655f2cd6ef954e191a79&summary=true&limit=1&after=WTI5dGJXVnVkRjlqZAFhKemIzSTZAOak0xTVRVMk9UZAzJOamcyTVRreU9qRTBPREl3TlRFNU5UWT0ZD'}}, 'shares': {'count': 6}, 'message': '\"একটি পরিচ্ছন্ন সরকারি হাসপাতাল\" কীভাবে সম্ভব হলো: হাসপাতালের যুগ্ম পরিচালক অধ্যাপক মো. বদরুল আলম প্রথম আলোকে বলেন, ‘দেশে অ্যাপোলো, ইউনাইটেড বা স্কয়ারের মতো ব্যয়বহুল হাসপাতাল আছে। এসব হাসপাতালে রোগীর কমতি নেই। কিন্তু দরিদ্র মানুষের আক্ষেপ, তাঁরা ওই সব হাসপাতালে যেতে পারেন না। সেই আক্ষেপ দূর করার একটা চেষ্টা এই হাসপাতাল তৈরির পেছনে কাজ করেছে। যেকোনো মানুষ এখানে এসে বলবে, অ্যাপোলো বা ইউনাইটেডে না গিয়ে ভুল করিনি।’\\n', 'likes': {'data': [{'name': 'Md Atiqur Rahman', 'id': '1768415670041755'}], 'summary': {'total_count': 45, 'has_liked': False, 'can_like': True}, 'paging': {'cursors': {'after': 'MTc2ODQxNTY3MDA0MTc1NQZDZD', 'before': 'MTc2ODQxNTY3MDA0MTc1NQZDZD'}, 'next': 'https://graph.facebook.com/v2.8/172177269650835_635087893359768/likes?access_token=1192796350809849%7C585a729a44bb655f2cd6ef954e191a79&summary=true&limit=1&after=MTc2ODQxNTY3MDA0MTc1NQZDZD'}}, 'created_time': '2016-12-18T05:20:31+0000', 'link': 'http://www.prothom-alo.com/bangladesh/article/1041863/%E0%A6%8F%E0%A6%95%E0%A6%9F%E0%A6%BF-%E0%A6%AA%E0%A6%B0%E0%A6%BF%E0%A6%9A%E0%A7%8D%E0%A6%9B%E0%A6%A8%E0%A7%8D%E0%A6%A8-%E0%A6%B8%E0%A6%B0%E0%A6%95%E0%A6%BE%E0%A6%B0%E0%A6%BF-%E0%A6%B9%E0%A6%BE%E0%A6%B8%E0%A6%AA%E0%A6%BE%E0%A6%A4%E0%A6%BE%E0%A6%B2'}], 'paging': {'previous': 'https://graph.facebook.com/v2.8/172177269650835/feed?fields=message,link,created_time,type,name,id,likes.limit%281%29.summary%28true%29,comments.limit%281%29.summary%28true%29,shares&limit=1&icon_size=16&since=1482112917&access_token=1192796350809849|585a729a44bb655f2cd6ef954e191a79&__paging_token=enc_AdCTiRjsjG7mqPGxLYqdwu8nLCjYgQCn4px8ZAxgLsAPyzD2P5TyZBXuZC1kdy1JrZCa0RtvN3NFY0s5U2I220hwhch8FhNfjLEIk2g7qrARkqDRRQZDZD&__previous=1', 'next': 'https://graph.facebook.com/v2.8/172177269650835/feed?fields=message,link,created_time,type,name,id,likes.limit%281%29.summary%28true%29,comments.limit%281%29.summary%28true%29,shares&limit=1&icon_size=16&access_token=1192796350809849|585a729a44bb655f2cd6ef954e191a79&until=1482112917&__paging_token=enc_AdCTiRjsjG7mqPGxLYqdwu8nLCjYgQCn4px8ZAxgLsAPyzD2P5TyZBXuZC1kdy1JrZCa0RtvN3NFY0s5U2I220hwhch8FhNfjLEIk2g7qrARkqDRRQZDZD'}}\n"
     ]
    }
   ],
   "source": [
    "def get_fb_group_data(group_id, access_token, num_statuses):\n",
    "\n",
    "    # Construct the URL string; see http://stackoverflow.com/a/37239851 for\n",
    "    # Reactions parameters\n",
    "    base = \"https://graph.facebook.com\"     # main url\n",
    "    node = \"/\" + group_id + \"/feed\" \n",
    "    parameters = \"/?fields=message,link,created_time,type,name,id,likes.limit(1).summary(true),comments.limit(1).summary(true),shares&limit=%s&access_token=%s\" % (num_statuses, access_token) # changed\n",
    "    url = base + node + parameters\n",
    "    print(url)\n",
    "\n",
    "    # retrieve data\n",
    "    data = json.loads(request_until_completed(url))\n",
    "\n",
    "    return data\n",
    "print(get_fb_group_data(group_id, access_token, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_reactions_of_each_status(status_id, access_token):\n",
    "\n",
    "    # See http://stackoverflow.com/a/37239851 for Reactions parameters\n",
    "        # Reactions are only accessable at a single-post endpoint\n",
    "\n",
    "    base = \"https://graph.facebook.com/v2.6\"\n",
    "    node = \"/%s\" % status_id\n",
    "    reactions = \"/?fields=\" \\\n",
    "            \"reactions.type(LIKE).limit(0).summary(total_count).as(like)\" \\\n",
    "            \",reactions.type(LOVE).limit(0).summary(total_count).as(love)\" \\\n",
    "            \",reactions.type(WOW).limit(0).summary(total_count).as(wow)\" \\\n",
    "            \",reactions.type(HAHA).limit(0).summary(total_count).as(haha)\" \\\n",
    "            \",reactions.type(SAD).limit(0).summary(total_count).as(sad)\" \\\n",
    "            \",reactions.type(ANGRY).limit(0).summary(total_count).as(angry)\"\n",
    "    parameters = \"&access_token=%s\" % access_token\n",
    "    url = base + node + reactions + parameters\n",
    "\n",
    "    # retrieve data\n",
    "    data = json.loads(request_until_completed(url))\n",
    "\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def process_fb_status(status, access_token):\n",
    "\n",
    "    # The status is now a Python dictionary, so for top-level items,\n",
    "    # we can simply call the key.\n",
    "\n",
    "    # Additionally, some items may not always exist,\n",
    "    # so must check for existence first\n",
    "\n",
    "    status_id = status['id']\n",
    "    status_message = '' if 'message' not in status.keys() else \\\n",
    "            unicode_normalize(status['message'])\n",
    "    link_name = '' if 'name' not in status.keys() else \\\n",
    "            unicode_normalize(status['name'])\n",
    "    status_type = status['type']\n",
    "    status_link = '' if 'link' not in status.keys() else \\\n",
    "            unicode_normalize(status['link'])\n",
    "\n",
    "    # Time needs special care since a) it's in UTC and\n",
    "    # b) it's not easy to use in statistical programs.\n",
    "\n",
    "    status_published = datetime.datetime.strptime(\n",
    "            status['created_time'],'%Y-%m-%dT%H:%M:%S+0000')\n",
    "    status_published = status_published + \\\n",
    "            datetime.timedelta(hours=-5) # EST\n",
    "    status_published = status_published.strftime(\n",
    "            '%Y-%m-%d %H:%M:%S') # best time format for spreadsheet programs\n",
    "\n",
    "    # Nested items require chaining dictionary keys.\n",
    "\n",
    "    num_reactions = 0 if 'reactions' not in status else \\\n",
    "            status['reactions']['summary']['total_count']\n",
    "    num_comments = 0 if 'comments' not in status else \\\n",
    "            status['comments']['summary']['total_count']\n",
    "    num_shares = 0 if 'shares' not in status else status['shares']['count']\n",
    "\n",
    "    # Counts of each reaction separately; good for sentiment\n",
    "    # Only check for reactions if past date of implementation:\n",
    "    # http://newsroom.fb.com/news/2016/02/reactions-now-available-globally/\n",
    "\n",
    "    reactions = get_reactions_of_each_status(status_id, access_token) if \\\n",
    "            status_published > '2016-02-24 00:00:00' else {}\n",
    "\n",
    "    num_likes = 0 if 'like' not in reactions else \\\n",
    "            reactions['like']['summary']['total_count']\n",
    "\n",
    "    # Special case: Set number of Likes to Number of reactions for pre-reaction\n",
    "    # statuses\n",
    "\n",
    "    num_likes = num_reactions if status_published < '2016-02-24 00:00:00' \\\n",
    "            else num_likes\n",
    "\n",
    "    def get_num_total_reactions(reaction_type, reactions):\n",
    "        if reaction_type not in reactions:\n",
    "            return 0\n",
    "        else:\n",
    "            return reactions[reaction_type]['summary']['total_count']\n",
    "\n",
    "    num_loves = get_num_total_reactions('love', reactions)\n",
    "    num_wows = get_num_total_reactions('wow', reactions)\n",
    "    num_hahas = get_num_total_reactions('haha', reactions)\n",
    "    num_sads = get_num_total_reactions('sad', reactions)\n",
    "    num_angrys = get_num_total_reactions('angry', reactions)\n",
    "\n",
    "    # Return a tuple of all processed data\n",
    "\n",
    "    return (status_id, status_message, link_name, status_type, status_link,\n",
    "            status_published, num_reactions, num_comments, num_shares,\n",
    "            num_likes, num_loves, num_wows, num_hahas, num_sads, num_angrys)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def scrape_fb_group_status(group_id, access_token):\n",
    "    with open('%s_facebook_statuses.csv' % group_id, 'w', newline='',encoding='utf-8') as file:\n",
    "        w = csv.writer(file)\n",
    "        w.writerow([\"status_id\", \"status_message\", \"link_name\", \"status_type\",\n",
    "                    \"status_link\", \"status_published\", \"num_reactions\", \n",
    "                    \"num_comments\", \"num_shares\", \"num_likes\", \"num_loves\", \n",
    "                    \"num_wows\", \"num_hahas\", \"num_sads\", \"num_angrys\"])\n",
    "\n",
    "        has_next_page = True\n",
    "        num_processed = 0   # keep a count on how many we've processed\n",
    "        scrape_starttime = datetime.datetime.now()\n",
    "\n",
    "        print(\"Scraping %s Facebook Page: %s\\n\" % (group_id, scrape_starttime))\n",
    "\n",
    "        statuses = get_fb_group_data(group_id, access_token, 100)\n",
    "\n",
    "        while has_next_page:\n",
    "            for status in statuses['data']:\n",
    "\n",
    "                # Ensure it is a status with the expected metadata\n",
    "#                 if 'reactions' in status:\n",
    "                w.writerow(process_fb_status(status,\n",
    "                        access_token))\n",
    "\n",
    "                # output progress occasionally to make sure code is not\n",
    "                # stalling\n",
    "                num_processed += 1\n",
    "                if num_processed % 100 == 0:\n",
    "                    print(\"%s Statuses Processed: %s\" % \\\n",
    "                        (num_processed, datetime.datetime.now()))\n",
    "\n",
    "            # if there is no next page, we're done.\n",
    "            if 'paging' in statuses.keys():\n",
    "                statuses = json.loads(request_until_completed(\n",
    "                                        statuses['paging']['next']))\n",
    "            else:\n",
    "                has_next_page = False\n",
    "\n",
    "\n",
    "        print(\"\\nDone!\\n%s Statuses Processed in %s\" % \\\n",
    "            (num_processed, datetime.datetime.now() - scrape_starttime))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping 172177269650835 Facebook Page: 2016-12-19 08:33:52.869184\n",
      "\n",
      "https://graph.facebook.com/172177269650835/feed/?fields=message,link,created_time,type,name,id,likes.limit(1).summary(true),comments.limit(1).summary(true),shares&limit=100&access_token=1192796350809849|585a729a44bb655f2cd6ef954e191a79\n",
      "100 Statuses Processed: 2016-12-19 08:35:06.527065\n",
      "200 Statuses Processed: 2016-12-19 08:36:12.452829\n",
      "300 Statuses Processed: 2016-12-19 08:37:17.915326\n",
      "400 Statuses Processed: 2016-12-19 08:38:22.971181\n",
      "500 Statuses Processed: 2016-12-19 08:39:29.060562\n",
      "600 Statuses Processed: 2016-12-19 08:40:48.207082\n",
      "700 Statuses Processed: 2016-12-19 08:42:08.045097\n",
      "800 Statuses Processed: 2016-12-19 08:43:19.311511\n",
      "900 Statuses Processed: 2016-12-19 08:44:25.086511\n",
      "1000 Statuses Processed: 2016-12-19 08:45:38.825358\n",
      "1100 Statuses Processed: 2016-12-19 08:46:43.686098\n",
      "1200 Statuses Processed: 2016-12-19 08:48:01.005216\n",
      "1300 Statuses Processed: 2016-12-19 08:49:13.418057\n",
      "1400 Statuses Processed: 2016-12-19 08:50:24.586243\n",
      "1500 Statuses Processed: 2016-12-19 08:51:33.315244\n",
      "1600 Statuses Processed: 2016-12-19 08:52:39.970847\n",
      "1700 Statuses Processed: 2016-12-19 08:53:45.621418\n",
      "1800 Statuses Processed: 2016-12-19 08:54:51.178693\n",
      "1900 Statuses Processed: 2016-12-19 08:56:04.870516\n",
      "2000 Statuses Processed: 2016-12-19 08:57:13.639828\n",
      "2100 Statuses Processed: 2016-12-19 08:58:25.066889\n",
      "2200 Statuses Processed: 2016-12-19 08:59:37.173092\n",
      "2300 Statuses Processed: 2016-12-19 09:00:50.350313\n",
      "2400 Statuses Processed: 2016-12-19 09:02:07.227957\n",
      "2500 Statuses Processed: 2016-12-19 09:03:11.152052\n",
      "2600 Statuses Processed: 2016-12-19 09:03:13.899506\n",
      "2700 Statuses Processed: 2016-12-19 09:03:17.699528\n",
      "2800 Statuses Processed: 2016-12-19 09:03:20.279573\n",
      "2900 Statuses Processed: 2016-12-19 09:03:23.179252\n",
      "3000 Statuses Processed: 2016-12-19 09:03:25.978102\n",
      "3100 Statuses Processed: 2016-12-19 09:03:28.537603\n",
      "3200 Statuses Processed: 2016-12-19 09:03:31.079532\n",
      "3300 Statuses Processed: 2016-12-19 09:03:33.743700\n",
      "3400 Statuses Processed: 2016-12-19 09:03:37.165244\n",
      "3500 Statuses Processed: 2016-12-19 09:03:39.792928\n",
      "3600 Statuses Processed: 2016-12-19 09:03:42.546441\n",
      "3700 Statuses Processed: 2016-12-19 09:03:45.115786\n",
      "3800 Statuses Processed: 2016-12-19 09:03:48.407657\n",
      "3900 Statuses Processed: 2016-12-19 09:03:51.089799\n",
      "4000 Statuses Processed: 2016-12-19 09:03:54.113847\n",
      "4100 Statuses Processed: 2016-12-19 09:03:57.456222\n",
      "4200 Statuses Processed: 2016-12-19 09:04:00.058839\n",
      "4300 Statuses Processed: 2016-12-19 09:04:02.790045\n",
      "4400 Statuses Processed: 2016-12-19 09:04:05.167168\n",
      "4500 Statuses Processed: 2016-12-19 09:04:07.592339\n",
      "4600 Statuses Processed: 2016-12-19 09:04:09.673954\n",
      "4700 Statuses Processed: 2016-12-19 09:04:11.990822\n",
      "4800 Statuses Processed: 2016-12-19 09:04:14.364915\n",
      "4900 Statuses Processed: 2016-12-19 09:04:17.260863\n",
      "5000 Statuses Processed: 2016-12-19 09:04:19.399075\n",
      "5100 Statuses Processed: 2016-12-19 09:04:21.559551\n",
      "5200 Statuses Processed: 2016-12-19 09:04:24.211315\n",
      "5300 Statuses Processed: 2016-12-19 09:04:26.303498\n",
      "5400 Statuses Processed: 2016-12-19 09:04:27.597036\n",
      "\n",
      "Done!\n",
      "5425 Statuses Processed in 0:30:35.752101\n"
     ]
    }
   ],
   "source": [
    "    scrape_fb_group_status(group_id, access_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
